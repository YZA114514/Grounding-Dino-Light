# ä¸‰äººåˆ†å·¥æ–¹æ¡ˆ - Jittor é‡å†™ä»»åŠ¡åˆ†è§£

---

## ğŸ¯ åˆ†å·¥åŸåˆ™

1. **è§£è€¦æ€§**ï¼šæ¯ä¸ªæ¨¡å—ç›¸å¯¹ç‹¬ç«‹ï¼Œæ¥å£æ¸…æ™°
2. **å¹¶è¡Œæ€§**ï¼šå¯ä»¥åŒæ—¶å¼€å‘ï¼Œå‡å°‘ç›¸äº’ç­‰å¾…
3. **éš¾åº¦å¹³è¡¡**ï¼šåˆç†åˆ†é…éš¾åº¦ï¼Œé¿å…ä¸€äººè´Ÿæ‹…è¿‡é‡
4. **ä¾èµ–å…³ç³»**ï¼šæ˜ç¡®æ¨¡å—é—´çš„ä¾èµ–ï¼Œå…ˆå®ç°è¢«ä¾èµ–çš„æ¨¡å—

---

## ğŸ“¦ æ¨¡å—ä¾èµ–å…³ç³»å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         æ•°æ®å±‚ï¼ˆæˆå‘˜Bï¼‰                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ æ•°æ®åŠ è½½å™¨    â”‚  â”‚ æ•°æ®é¢„å¤„ç†    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         æ¨¡å‹å±‚ï¼ˆæˆå‘˜Aï¼‰                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Swin Backboneâ”‚  â”‚ Transformer  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ MSDeformAttn â”‚  â”‚ DINO Head    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    å®Œæ•´æ¨¡å‹ç»„è£…                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     æ–‡æœ¬ä¸è®­ç»ƒå±‚ï¼ˆæˆå‘˜Cï¼‰                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ BERTåŒ…è£…å™¨    â”‚  â”‚ ç‰¹å¾èåˆ      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ æŸå¤±å‡½æ•°      â”‚  â”‚ è®­ç»ƒè„šæœ¬      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ è¯„ä¼°è„šæœ¬      â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ è¯¦ç»†åˆ†å·¥æ–¹æ¡ˆ

### ğŸ‘¤ æˆå‘˜ Aæ ¸å¿ƒæ¨¡å‹æ¶æ„

#### èŒè´£èŒƒå›´
è´Ÿè´£æ‰€æœ‰**æ¨¡å‹æ¶æ„**ç›¸å…³çš„å®ç°ï¼ŒåŒ…æ‹¬å›¾åƒç¼–ç ã€Transformerã€æ£€æµ‹å¤´ç­‰ã€‚

#### å…·ä½“ä»»åŠ¡

##### 1. Swin Transformer Backbone â­â­â­
**æ—¶é—´**: 2-3 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/models/backbone/swin_transformer.py
class SwinTransformer(nn.Module):
    """Swin-T å›¾åƒç¼–ç å™¨"""
    def __init__(self, ...):
        # å®ç° Swin-T çš„å®Œæ•´ç»“æ„
        pass
    
    def execute(self, x):
        # è¿”å›å¤šå°ºåº¦ç‰¹å¾å›¾
        return features
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: `(B, 3, H, W)` å›¾åƒ
- è¾“å‡º: å¤šå°ºåº¦ç‰¹å¾å›¾åˆ—è¡¨ `[feat1, feat2, feat3, feat4]`

**å‚è€ƒèµ„æº**ï¼š
- JDet åº“ä¸­çš„ Swin å®ç°
- PyTorch å®˜æ–¹ Swin Transformer

---

##### 2. Multi-Scale Deformable Attention â­â­â­â­â­
**æ—¶é—´**: 3-5 å¤©  
**ä¼˜å…ˆçº§**: P0ï¼ˆæœ€å¤æ‚ï¼‰

```python
# æ–‡ä»¶: jittor_implementation/models/attention/ms_deform_attn.py
class MSDeformAttn(nn.Module):
    """å¤šå°ºåº¦å¯å˜å½¢æ³¨æ„åŠ›"""
    def __init__(self, ...):
        pass
    
    def execute(self, value, spatial_shapes, ...):
        # å®ç°å¤šå°ºåº¦å¯å˜å½¢æ³¨æ„åŠ›
        pass
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: `value`, `spatial_shapes`, `sampling_locations`, `attention_weights`
- è¾“å‡º: æ³¨æ„åŠ›è¾“å‡ºç‰¹å¾

**å®ç°ç­–ç•¥**ï¼š
1. **ä¼˜å…ˆæ–¹æ¡ˆ**ï¼šä½¿ç”¨ JDet çš„ç°æœ‰å®ç°
2. **å¤‡é€‰æ–¹æ¡ˆ**ï¼šä» PyTorch ç§»æ¤ï¼Œå¯èƒ½éœ€è¦æ‰‹å†™ CUDA kernel

---

##### 3. Transformer Encoder â­â­â­
**æ—¶é—´**: 2 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/models/transformer/encoder.py
class TransformerEncoder(nn.Module):
    """Transformer Encoder"""
    def __init__(self, ...):
        # ä½¿ç”¨ MSDeformAttn
        self.attn = MSDeformAttn(...)
        pass
    
    def execute(self, features, pos_emb):
        # Encoder å‰å‘ä¼ æ’­
        pass
```

**ä¾èµ–**ï¼š
- éœ€è¦æˆå‘˜Aè‡ªå·±å®ç°çš„ MSDeformAttn

---

##### 4. Transformer Decoder (DINOé£æ ¼) â­â­â­
**æ—¶é—´**: 2-3 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/models/transformer/decoder.py
class TransformerDecoder(nn.Module):
    """DINO é£æ ¼çš„ Transformer Decoder"""
    def __init__(self, ...):
        pass
    
    def execute(self, queries, encoder_output, ...):
        # Decoder å‰å‘ä¼ æ’­
        pass
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: `queries`, `encoder_output`, `text_features`
- è¾“å‡º: è§£ç åçš„ç‰¹å¾

---

##### 5. DINO æ£€æµ‹å¤´ â­â­â­
**æ—¶é—´**: 2 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/models/head/dino_head.py
class DINOHead(nn.Module):
    """DINO æ£€æµ‹å¤´"""
    def __init__(self, ...):
        pass
    
    def execute(self, decoder_output):
        # è¾“å‡ºåˆ†ç±»å’Œè¾¹ç•Œæ¡†
        return pred_logits, pred_boxes
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: Decoder è¾“å‡ºç‰¹å¾
- è¾“å‡º: `(pred_logits, pred_boxes)`

---

##### 6. å®Œæ•´æ¨¡å‹ç»„è£… â­â­â­
**æ—¶é—´**: 2-3 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/models/groundingdino.py
class GroundingDINO(nn.Module):
    """å®Œæ•´çš„ Grounding DINO æ¨¡å‹"""
    def __init__(self, ...):
        # ç»„è£…æ‰€æœ‰æ¨¡å—
        self.backbone = SwinTransformer(...)
        self.encoder = TransformerEncoder(...)
        self.decoder = TransformerDecoder(...)
        self.head = DINOHead(...)
        # æ³¨æ„ï¼štext_encoder å’Œ fusion ç”±æˆå‘˜Cå®ç°
    
    def execute(self, images, text_features):
        # å®Œæ•´å‰å‘ä¼ æ’­
        # 1. å›¾åƒç¼–ç 
        visual_features = self.backbone(images)
        # 2. Encoder
        encoder_output = self.encoder(visual_features)
        # 3. Decoderï¼ˆéœ€è¦ text_featuresï¼‰
        decoder_output = self.decoder(queries, encoder_output, text_features)
        # 4. æ£€æµ‹å¤´
        return self.head(decoder_output)
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: `images` (B, 3, H, W), `text_features` (ç”±æˆå‘˜Cæä¾›)
- è¾“å‡º: `(pred_logits, pred_boxes)`

**ä¾èµ–**ï¼š
- éœ€è¦æˆå‘˜Cæä¾›çš„ `text_features`ï¼ˆå¯ä»¥å…ˆå®šä¹‰æ¥å£ï¼Œç”¨å ä½ç¬¦ï¼‰

---

##### 7. æƒé‡è½¬æ¢è„šæœ¬ â­â­
**æ—¶é—´**: 1 å¤©  
**ä¼˜å…ˆçº§**: P1

```python
# æ–‡ä»¶: scripts/convert_weights_pytorch_to_jittor.py
def convert_weights(pytorch_path, jittor_path):
    """è½¬æ¢ PyTorch æƒé‡åˆ° Jittor"""
    # åŠ è½½ PyTorch æƒé‡
    # è½¬æ¢å¹¶ä¿å­˜ä¸º Jittor æ ¼å¼
    pass
```

---

#### æˆå‘˜Açš„å·¥ä½œæ¸…å•

| ä»»åŠ¡ | éš¾åº¦ | æ—¶é—´ | ä¾èµ– |
|------|------|------|------|
| Swin Transformer Backbone | â­â­â­ | 2-3å¤© | æ—  |
| Multi-Scale Deformable Attention | â­â­â­â­â­ | 3-5å¤© | æ—  |
| Transformer Encoder | â­â­â­ | 2å¤© | MSDeformAttn |
| Transformer Decoder | â­â­â­ | 2-3å¤© | Encoder |
| DINO æ£€æµ‹å¤´ | â­â­â­ | 2å¤© | Decoder |
| å®Œæ•´æ¨¡å‹ç»„è£… | â­â­â­ | 2-3å¤© | æ‰€æœ‰æ¨¡å— + æˆå‘˜Cçš„æ¥å£ |
| æƒé‡è½¬æ¢è„šæœ¬ | â­â­ | 1å¤© | æ¨¡å‹å®ç°å®Œæˆ |
| **æ€»è®¡** | | **14-20å¤©** | |

---

### ğŸ‘¤ æˆå‘˜ B- æ•°æ®å¤„ç†ä¸è¯„ä¼°

#### èŒè´£èŒƒå›´
è´Ÿè´£æ‰€æœ‰**æ•°æ®å¤„ç†**ã€**æ•°æ®åŠ è½½**å’Œ**è¯„ä¼°**ç›¸å…³çš„å®ç°ã€‚

#### å…·ä½“ä»»åŠ¡

##### 1. æ•°æ®æ ¼å¼è½¬æ¢è„šæœ¬ â­
**æ—¶é—´**: 1 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: scripts/coco2odvg.py
def coco_to_odvg(coco_path, output_path):
    """COCO æ ¼å¼è½¬ ODVG æ ¼å¼"""
    # å¯ä»¥å¤ç”¨ PyTorch ç‰ˆæœ¬çš„é€»è¾‘
    pass

# æ–‡ä»¶: scripts/goldg2odvg.py
def goldg_to_odvg(goldg_path, output_path):
    """GoldG æ ¼å¼è½¬ ODVG æ ¼å¼"""
    pass
```

**è¯´æ˜**ï¼šè¿™éƒ¨åˆ†é€»è¾‘ä¸æ¡†æ¶æ— å…³ï¼Œå¯ä»¥å®Œå…¨å¤ç”¨ã€‚

---

##### 2. æ•°æ®é¢„å¤„ç†æ¨¡å— â­
**æ—¶é—´**: 1 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/data/transforms.py
import jittor.transform as transform

def build_transforms(is_train=True):
    """æ„å»ºæ•°æ®é¢„å¤„ç†ç®¡é“"""
    if is_train:
        return transform.Compose([
            transform.Resize((800, 1333)),
            transform.RandomHorizontalFlip(),
            transform.ToTensor(),
            transform.ImageNormalize(...)
        ])
    else:
        return transform.Compose([
            transform.Resize((800, 1333)),
            transform.ToTensor(),
            transform.ImageNormalize(...)
        ])
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: PIL Image
- è¾“å‡º: Jittor Tensor

---

##### 3. LVIS æ•°æ®åŠ è½½å™¨ â­â­
**æ—¶é—´**: 2 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/data/lvis_dataset.py
import jittor as jt
from jittor.dataset import Dataset

class LVISDataset(Dataset):
    """LVIS æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, anno_path, image_dir, transforms=None):
        # åŠ è½½æ ‡æ³¨æ–‡ä»¶
        # åˆå§‹åŒ–å›¾ç‰‡è·¯å¾„
        pass
    
    def __getitem__(self, idx):
        # åŠ è½½å›¾ç‰‡
        image = load_image(self.image_paths[idx])
        # åŠ è½½æ ‡æ³¨
        annotations = self.annotations[idx]
        # åº”ç”¨é¢„å¤„ç†
        if self.transforms:
            image = self.transforms(image)
        return image, annotations
    
    def __len__(self):
        return len(self.images)
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å‡º: `(image_tensor, annotation_dict)`
- `annotation_dict` åŒ…å«: `boxes`, `labels`, `categories`

**ä¾èµ–**ï¼š
- éœ€è¦æˆå‘˜Bè‡ªå·±å®ç°çš„æ•°æ®é¢„å¤„ç†

---

##### 4. æ•°æ®é‡‡æ ·ç­–ç•¥ â­â­
**æ—¶é—´**: 1-2 å¤©  
**ä¼˜å…ˆçº§**: P1

```python
# æ–‡ä»¶: jittor_implementation/data/sampler.py
class LVISSampler:
    """LVIS é•¿å°¾åˆ†å¸ƒé‡‡æ ·ç­–ç•¥"""
    def __init__(self, dataset, ...):
        # å®ç°ç±»åˆ«å¹³è¡¡é‡‡æ ·
        pass
```

**è¯´æ˜**ï¼šLVIS æ˜¯é•¿å°¾åˆ†å¸ƒï¼Œéœ€è¦ç‰¹æ®Šé‡‡æ ·ç­–ç•¥ã€‚

---

##### 5. æŸå¤±å‡½æ•° â­â­
**æ—¶é—´**: 2 å¤©  
**ä¼˜å…ˆçº§**: P1

```python
# æ–‡ä»¶: jittor_implementation/losses/focal_loss.py
class FocalLoss(nn.Module):
    """Focal Loss for åˆ†ç±»"""
    def execute(self, pred, target, alpha=0.25, gamma=2.0):
        pass

# æ–‡ä»¶: jittor_implementation/losses/giou_loss.py
class GIoULoss(nn.Module):
    """GIoU Loss for è¾¹ç•Œæ¡†"""
    def execute(self, pred_boxes, target_boxes):
        pass

# æ–‡ä»¶: jittor_implementation/losses/l1_loss.py
class L1Loss(nn.Module):
    """L1 Loss for è¾¹ç•Œæ¡†"""
    def execute(self, pred_boxes, target_boxes):
        pass

# æ–‡ä»¶: jittor_implementation/losses/grounding_loss.py
class GroundingLoss(nn.Module):
    """Grounding DINO æ€»æŸå¤±"""
    def __init__(self):
        self.focal_loss = FocalLoss()
        self.giou_loss = GIoULoss()
        self.l1_loss = L1Loss()
    
    def execute(self, pred_logits, pred_boxes, targets):
        # ç»„åˆæ‰€æœ‰æŸå¤±
        loss_ce = self.focal_loss(pred_logits, targets['labels'])
        loss_bbox = self.l1_loss(pred_boxes, targets['boxes'])
        loss_giou = self.giou_loss(pred_boxes, targets['boxes'])
        return loss_ce + 5 * loss_bbox + 2 * loss_giou
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: æ¨¡å‹è¾“å‡º `(pred_logits, pred_boxes)` å’Œ `targets`
- è¾“å‡º: æ ‡é‡æŸå¤±å€¼

**ä¾èµ–**ï¼š
- éœ€è¦æˆå‘˜Açš„æ¨¡å‹è¾“å‡ºæ ¼å¼

---

##### 6. LVIS è¯„ä¼°è„šæœ¬ â­â­
**æ—¶é—´**: 2 å¤©  
**ä¼˜å…ˆçº§**: P1

```python
# æ–‡ä»¶: jittor_implementation/eval/lvis_evaluator.py
class LVISEvaluator:
    """LVIS è¯„ä¼°å™¨"""
    def __init__(self, ...):
        pass
    
    def evaluate(self, model, dataloader):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        # æ”¶é›†æ‰€æœ‰é¢„æµ‹ç»“æœ
        # è®¡ç®— AP, APr, APc, APf
        return {
            'AP': 52.1,
            'APr': 35.4,
            'APc': 51.3,
            'APf': 55.7
        }
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: `model`, `dataloader`
- è¾“å‡º: è¯„ä¼°æŒ‡æ ‡å­—å…¸

**ä¾èµ–**ï¼š
- éœ€è¦æˆå‘˜Açš„å®Œæ•´æ¨¡å‹
- éœ€è¦æˆå‘˜Bçš„æ•°æ®åŠ è½½å™¨

---

#### æˆå‘˜Bçš„å·¥ä½œæ¸…å•

| ä»»åŠ¡ | éš¾åº¦ | æ—¶é—´ | ä¾èµ– |
|------|------|------|------|
| æ•°æ®æ ¼å¼è½¬æ¢è„šæœ¬ | â­ | 1å¤© | æ—  |
| æ•°æ®é¢„å¤„ç†æ¨¡å— | â­ | 1å¤© | æ—  |
| LVIS æ•°æ®åŠ è½½å™¨ | â­â­ | 2å¤© | æ•°æ®é¢„å¤„ç† |
| æ•°æ®é‡‡æ ·ç­–ç•¥ | â­â­ | 1-2å¤© | æ•°æ®åŠ è½½å™¨ |
| æŸå¤±å‡½æ•° | â­â­ | 2å¤© | æ¨¡å‹è¾“å‡ºæ ¼å¼ï¼ˆæˆå‘˜Aï¼‰ |
| LVIS è¯„ä¼°è„šæœ¬ | â­â­ | 2å¤© | å®Œæ•´æ¨¡å‹ï¼ˆæˆå‘˜Aï¼‰ |
| **æ€»è®¡** | | **9-10å¤©** | |

---

### ğŸ‘¤ æˆå‘˜ C- æ–‡æœ¬ç¼–ç ä¸è®­ç»ƒ

#### èŒè´£èŒƒå›´
è´Ÿè´£**æ–‡æœ¬ç¼–ç **ã€**ç‰¹å¾èåˆ**ã€**è®­ç»ƒæµç¨‹**å’Œ**å¯¹æ¯”å®éªŒ**ã€‚

#### å…·ä½“ä»»åŠ¡

##### 1. BERT æ–‡æœ¬ç¼–ç å™¨åŒ…è£… â­
**æ—¶é—´**: 1 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/models/text_encoder/bert_wrapper.py
import jittor as jt
from transformers import BertModel, BertTokenizer

class BERTWrapper(nn.Module):
    """BERT æ–‡æœ¬ç¼–ç å™¨åŒ…è£…"""
    def __init__(self, model_name='bert-base-uncased'):
        self.bert = BertModel.from_pretrained(model_name)
        self.tokenizer = BertTokenizer.from_pretrained(model_name)
    
    def execute(self, text):
        # Tokenize
        tokens = self.tokenizer(text, return_tensors='pt', padding=True)
        # BERT å‰å‘ä¼ æ’­ï¼ˆPyTorchï¼‰
        with torch.no_grad():
            outputs = self.bert(**tokens)
        # è½¬æ¢ä¸º Jittor tensor
        return jt.array(outputs.last_hidden_state.numpy())
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: æ–‡æœ¬å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
- è¾“å‡º: `(B, L, D)` æ–‡æœ¬ç‰¹å¾

**è¯´æ˜**ï¼šBERT å¯ä»¥å…ˆç”¨ PyTorch ç‰ˆæœ¬ï¼Œåç»­å¯ä»¥å®Œå…¨ç”¨ Jittor é‡å†™ã€‚

---

##### 2. å­å¥çº§æ–‡æœ¬å¤„ç† â­â­
**æ—¶é—´**: 1-2 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/models/text_encoder/text_processor.py
class TextProcessor:
    """æ–‡æœ¬é¢„å¤„ç†ï¼ŒåŒ…æ‹¬å­å¥çº§å¤„ç†"""
    def __init__(self):
        pass
    
    def process(self, text, categories):
        """
        å¤„ç†æ–‡æœ¬ï¼Œæ„å»ºå­å¥çº§è¡¨å¾
        ä¾‹å¦‚: "person . dog . cat" -> å­å¥åˆ—è¡¨
        """
        # åˆ†å‰²å­å¥
        phrases = text.split(' . ')
        # æ„å»ºæ³¨æ„åŠ›æ©ç 
        attention_mask = self.build_attention_mask(phrases, categories)
        return phrases, attention_mask
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: æ–‡æœ¬å­—ç¬¦ä¸²ï¼Œç±»åˆ«åˆ—è¡¨
- è¾“å‡º: å¤„ç†åçš„æ–‡æœ¬å’Œæ³¨æ„åŠ›æ©ç 

---

##### 3. è·¨æ¨¡æ€ç‰¹å¾èåˆæ¨¡å— â­â­
**æ—¶é—´**: 2 å¤©  
**ä¼˜å…ˆçº§**: P0

```python
# æ–‡ä»¶: jittor_implementation/models/fusion/feature_fusion.py
class FeatureFusion(nn.Module):
    """è§†è§‰-è¯­è¨€ç‰¹å¾èåˆ"""
    def __init__(self, ...):
        # å®ç°èåˆå±‚
        pass
    
    def execute(self, visual_features, text_features):
        """
        èåˆè§†è§‰å’Œæ–‡æœ¬ç‰¹å¾
        """
        # èåˆé€»è¾‘
        fused_features = self.fusion_layer(visual_features, text_features)
        return fused_features
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: `visual_features` (æ¥è‡ªæˆå‘˜A), `text_features` (æ¥è‡ªBERT)
- è¾“å‡º: èåˆåçš„ç‰¹å¾

**ä¾èµ–**ï¼š
- éœ€è¦æˆå‘˜Açš„è§†è§‰ç‰¹å¾æ ¼å¼
- éœ€è¦æˆå‘˜Cè‡ªå·±çš„æ–‡æœ¬ç‰¹å¾

---

##### 4. è¯­è¨€å¼•å¯¼ Query ç”Ÿæˆ â­â­
**æ—¶é—´**: 1-2 å¤©  
**ä¼˜å…ˆçº§**: P1

```python
# æ–‡ä»¶: jittor_implementation/models/query/language_guided_query.py
class LanguageGuidedQuery(nn.Module):
    """è¯­è¨€å¼•å¯¼çš„ Query ç”Ÿæˆ"""
    def __init__(self, ...):
        pass
    
    def execute(self, text_features):
        """æ ¹æ®æ–‡æœ¬ç‰¹å¾ç”Ÿæˆ query"""
        queries = self.query_generator(text_features)
        return queries
```

**æ¥å£å®šä¹‰**ï¼š
- è¾“å…¥: æ–‡æœ¬ç‰¹å¾
- è¾“å‡º: Query å‘é‡

---

##### 5. è®­ç»ƒè„šæœ¬ â­â­
**æ—¶é—´**: 2-3 å¤©  
**ä¼˜å…ˆçº§**: P1

```python
# æ–‡ä»¶: jittor_implementation/train/trainer.py
class Trainer:
    """è®­ç»ƒå™¨"""
    def __init__(self, model, dataloader, optimizer, loss_fn):
        self.model = model
        self.dataloader = dataloader
        self.optimizer = optimizer
        self.loss_fn = loss_fn
    
    def train_one_epoch(self):
        """è®­ç»ƒä¸€ä¸ª epoch"""
        for batch in self.dataloader:
            images, texts, targets = batch
            # æ–‡æœ¬ç¼–ç 
            text_features = self.text_encoder(texts)
            # æ¨¡å‹å‰å‘ä¼ æ’­
            outputs = self.model(images, text_features)
            # è®¡ç®—æŸå¤±
            loss = self.loss_fn(outputs, targets)
            # åå‘ä¼ æ’­
            self.optimizer.step(loss)
    
    def train(self, epochs):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        for epoch in range(epochs):
            self.train_one_epoch()
            # è¯„ä¼°
            metrics = self.evaluator.evaluate(self.model, self.val_loader)
```

**æ¥å£å®šä¹‰**ï¼š
- æ•´åˆæˆå‘˜Açš„æ¨¡å‹ã€æˆå‘˜Bçš„æ•°æ®åŠ è½½å™¨å’ŒæŸå¤±å‡½æ•°

**ä¾èµ–**ï¼š
- éœ€è¦æˆå‘˜Açš„å®Œæ•´æ¨¡å‹
- éœ€è¦æˆå‘˜Bçš„æ•°æ®åŠ è½½å™¨å’ŒæŸå¤±å‡½æ•°
- éœ€è¦æˆå‘˜Cçš„æ–‡æœ¬ç¼–ç å™¨

---

##### 6. è®­ç»ƒé…ç½®å’Œå·¥å…· â­
**æ—¶é—´**: 1 å¤©  
**ä¼˜å…ˆçº§**: P1

```python
# æ–‡ä»¶: jittor_implementation/train/config.py
# è®­ç»ƒè¶…å‚æ•°é…ç½®

# æ–‡ä»¶: jittor_implementation/train/utils.py
# è®­ç»ƒå·¥å…·å‡½æ•°ï¼ˆcheckpointä¿å­˜ã€æ—¥å¿—ç­‰ï¼‰
```

---

##### 7. å¯¹æ¯”å®éªŒï¼ˆæ‰©å±•ä»»åŠ¡ï¼‰ â­â­â­
**æ—¶é—´**: 3-5 å¤©  
**ä¼˜å…ˆçº§**: P2ï¼ˆå¯é€‰ï¼‰

```python
# æ–‡ä»¶: jittor_implementation/experiments/vlm_comparison.py
# ä¸ VLM æ¨¡å‹çš„å¯¹æ¯”å®éªŒ
```

---

#### æˆå‘˜Cçš„å·¥ä½œæ¸…å•

| ä»»åŠ¡ | éš¾åº¦ | æ—¶é—´ | ä¾èµ– |
|------|------|------|------|
| BERT æ–‡æœ¬ç¼–ç å™¨åŒ…è£… | â­ | 1å¤© | æ—  |
| å­å¥çº§æ–‡æœ¬å¤„ç† | â­â­ | 1-2å¤© | BERT |
| è·¨æ¨¡æ€ç‰¹å¾èåˆ | â­â­ | 2å¤© | æ–‡æœ¬ç‰¹å¾ + è§†è§‰ç‰¹å¾æ¥å£ |
| è¯­è¨€å¼•å¯¼ Query ç”Ÿæˆ | â­â­ | 1-2å¤© | æ–‡æœ¬ç‰¹å¾ |
| è®­ç»ƒè„šæœ¬ | â­â­ | 2-3å¤© | æ¨¡å‹ï¼ˆæˆå‘˜Aï¼‰+ æ•°æ®ï¼ˆæˆå‘˜Bï¼‰ |
| è®­ç»ƒé…ç½®å’Œå·¥å…· | â­ | 1å¤© | è®­ç»ƒè„šæœ¬ |
| å¯¹æ¯”å®éªŒï¼ˆå¯é€‰ï¼‰ | â­â­â­ | 3-5å¤© | å®Œæ•´ç³»ç»Ÿ |
| **æ€»è®¡** | | **9-15å¤©** | |

---

## ğŸ”— æ¨¡å—æ¥å£å®šä¹‰

### å…³é”®æ¥å£ï¼ˆéœ€è¦æå‰çº¦å®šï¼‰

#### 1. æ¨¡å‹è¾“å…¥è¾“å‡ºæ¥å£

```python
# æ–‡ä»¶: jittor_implementation/models/interfaces.py

# æ¨¡å‹è¾“å…¥
class ModelInput:
    images: jt.Var  # (B, 3, H, W)
    text_features: jt.Var  # (B, L, D) - ç”±æˆå‘˜Cæä¾›

# æ¨¡å‹è¾“å‡º
class ModelOutput:
    pred_logits: jt.Var  # (B, N, num_classes)
    pred_boxes: jt.Var  # (B, N, 4)
```

#### 2. æ•°æ®æ¥å£

```python
# æ•°æ®åŠ è½½å™¨è¾“å‡º
class BatchData:
    images: jt.Var  # (B, 3, H, W)
    annotations: dict  # {'boxes': ..., 'labels': ..., 'categories': ...}
    texts: list  # æ–‡æœ¬åˆ—è¡¨
```

#### 3. æ–‡æœ¬ç‰¹å¾æ¥å£

```python
# æ–‡æœ¬ç¼–ç å™¨è¾“å‡º
class TextFeatures:
    features: jt.Var  # (B, L, D)
    attention_mask: jt.Var  # (B, L)
```

---

## ğŸ“… å¹¶è¡Œå¼€å‘æ—¶é—´çº¿

### Week 1: åŸºç¡€æ¨¡å—ï¼ˆå¹¶è¡Œå¼€å‘ï¼‰

| æˆå‘˜ | ä»»åŠ¡ | å¯å¹¶è¡Œ |
|------|------|--------|
| **æˆå‘˜A** | Swin Backbone | âœ… |
| **æˆå‘˜B** | æ•°æ®åŠ è½½å™¨ | âœ… |
| **æˆå‘˜C** | BERT åŒ…è£…å™¨ | âœ… |

### Week 2: æ ¸å¿ƒæ¨¡å—ï¼ˆéƒ¨åˆ†ä¾èµ–ï¼‰

| æˆå‘˜ | ä»»åŠ¡ | ä¾èµ– |
|------|------|------|
| **æˆå‘˜A** | MSDeformAttn, Transformer | è‡ªå·±çš„ Swin |
| **æˆå‘˜B** | æŸå¤±å‡½æ•° | éœ€è¦æ¨¡å‹è¾“å‡ºæ ¼å¼ï¼ˆæ¥å£ï¼‰ |
| **æˆå‘˜C** | æ–‡æœ¬å¤„ç†, ç‰¹å¾èåˆ | éœ€è¦è§†è§‰ç‰¹å¾æ¥å£ |

### Week 3: é›†æˆä¸è®­ç»ƒï¼ˆéœ€è¦åä½œï¼‰

| æˆå‘˜ | ä»»åŠ¡ | ä¾èµ– |
|------|------|------|
| **æˆå‘˜A** | æ¨¡å‹ç»„è£… | éœ€è¦æˆå‘˜Cçš„æ–‡æœ¬ç‰¹å¾æ¥å£ |
| **æˆå‘˜B** | è¯„ä¼°è„šæœ¬ | éœ€è¦å®Œæ•´æ¨¡å‹ |
| **æˆå‘˜C** | è®­ç»ƒè„šæœ¬ | éœ€è¦å®Œæ•´æ¨¡å‹å’Œæ•°æ® |

---

## ğŸ¯ å…³é”®é‡Œç¨‹ç¢‘

### é‡Œç¨‹ç¢‘ 1: æ¥å£å®šä¹‰ï¼ˆDay 1ï¼‰
- **å…¨ä½“**ï¼šå…±åŒå®šä¹‰æ‰€æœ‰æ¨¡å—æ¥å£
- **äº§å‡º**ï¼š`interfaces.py` æ–‡ä»¶

### é‡Œç¨‹ç¢‘ 2: åŸºç¡€æ¨¡å—å®Œæˆï¼ˆWeek 1 ç»“æŸï¼‰
- **æˆå‘˜A**ï¼šSwin Backbone å¯ç”¨
- **æˆå‘˜B**ï¼šæ•°æ®åŠ è½½å™¨å¯ç”¨
- **æˆå‘˜C**ï¼šBERT ç¼–ç å™¨å¯ç”¨

### é‡Œç¨‹ç¢‘ 3: æ ¸å¿ƒæ¨¡å—å®Œæˆï¼ˆWeek 2 ç»“æŸï¼‰
- **æˆå‘˜A**ï¼šå®Œæ•´æ¨¡å‹æ¶æ„
- **æˆå‘˜B**ï¼šæŸå¤±å‡½æ•°å’Œè¯„ä¼°
- **æˆå‘˜C**ï¼šç‰¹å¾èåˆå’Œè®­ç»ƒè„šæœ¬

### é‡Œç¨‹ç¢‘ 4: é›†æˆæµ‹è¯•ï¼ˆWeek 3 å¼€å§‹ï¼‰
- **å…¨ä½“**ï¼šé›†æˆæ‰€æœ‰æ¨¡å—
- **æµ‹è¯•**ï¼šç«¯åˆ°ç«¯æµç¨‹éªŒè¯

---

## ğŸ’¡ åä½œå»ºè®®

### 1. æ¯æ—¥ç«™ä¼šï¼ˆ15åˆ†é’Ÿï¼‰
- åŒæ­¥è¿›åº¦
- è®¨è®ºæ¥å£é—®é¢˜
- è§£å†³ä¾èµ–å†²çª

### 2. æ¥å£ä¼˜å…ˆ
- å…ˆå®šä¹‰æ¥å£ï¼Œå†å®ç°
- ä½¿ç”¨å ä½ç¬¦/æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•

### 3. ç‰ˆæœ¬æ§åˆ¶
- ä½¿ç”¨ Git åˆ†æ”¯
- åŠæ—¶æäº¤å’Œåˆå¹¶
- ä»£ç å®¡æŸ¥

### 4. æµ‹è¯•é©±åŠ¨
- æ¯ä¸ªæ¨¡å—å®ç°åç«‹å³æµ‹è¯•
- ä¸ PyTorch ç‰ˆæœ¬å¯¹æ¯”è¾“å‡º

---

## ğŸ“Š å·¥ä½œé‡ç»Ÿè®¡

| æˆå‘˜ | æ ¸å¿ƒä»»åŠ¡ | æ€»æ—¶é—´ | éš¾åº¦åˆ†å¸ƒ |
|------|---------|--------|---------|
| **æˆå‘˜A** | 7 ä¸ªä»»åŠ¡ | 14-20 å¤© | é«˜éš¾åº¦ï¼ˆMSDeformAttnï¼‰ |
| **æˆå‘˜B** | 6 ä¸ªä»»åŠ¡ | 9-10 å¤© | ä¸­ç­‰éš¾åº¦ |
| **æˆå‘˜C** | 7 ä¸ªä»»åŠ¡ | 9-15 å¤© | ä¸­ç­‰éš¾åº¦ |

**æ€»å·¥ä½œé‡**ï¼š32-45 å¤©ï¼ˆ3äººå¹¶è¡Œï¼Œå®é™…çº¦ 3-4 å‘¨ï¼‰

---

## âœ… æ£€æŸ¥æ¸…å•

### Week 1 ç»“æŸæ£€æŸ¥
- [ ] æˆå‘˜A: Swin Backbone å®ç°å®Œæˆ
- [ ] æˆå‘˜B: æ•°æ®åŠ è½½å™¨å¯ç”¨
- [ ] æˆå‘˜C: BERT ç¼–ç å™¨å¯ç”¨
- [ ] å…¨ä½“: æ¥å£å®šä¹‰å®Œæˆ

### Week 2 ç»“æŸæ£€æŸ¥
- [ ] æˆå‘˜A: å®Œæ•´æ¨¡å‹æ¶æ„å®ç°
- [ ] æˆå‘˜B: æŸå¤±å‡½æ•°å’Œè¯„ä¼°è„šæœ¬å®Œæˆ
- [ ] æˆå‘˜C: ç‰¹å¾èåˆå’Œè®­ç»ƒè„šæœ¬å®Œæˆ

### Week 3 ç»“æŸæ£€æŸ¥
- [ ] å…¨ä½“: ç«¯åˆ°ç«¯æµç¨‹éªŒè¯é€šè¿‡
- [ ] æƒé‡è½¬æ¢æˆåŠŸ
- [ ] å¯ä»¥å¼€å§‹è®­ç»ƒ

---

**æœ€åæ›´æ–°**: 2025-11-29

